{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c17a57c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Regression with Evaluation metrics\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "column_names = ['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD', 'TAX', 'PTRATIO', 'B', 'LSTAT', 'MEDV']\n",
    "data = pd.read_csv('D:\\\\AppStoneLab\\\\Day 2\\\\housing.csv', header=None, delimiter=r\"\\s+\", names=column_names)\n",
    "\n",
    "X=data.drop('MEDV', axis=1)\n",
    "y=data['MEDV']\n",
    "\n",
    "X_train, X_test, y_train, y_test= train_test_split(X, y, test_size=0.25, random_state=100)\n",
    "\n",
    "LR=LinearRegression()\n",
    "LR.fit(X_train, y_train)\n",
    "y_pred=LR.predict(X_test)\n",
    "print(\"Before normalization : \\n\")\n",
    "MAE=mean_absolute_error(y_test, y_pred)\n",
    "print(\"MAE: \", MAE)\n",
    "\n",
    "MSE=mean_squared_error(y_test, y_pred)\n",
    "print(\"MSE: \", MSE)\n",
    "\n",
    "r2=r2_score(y_test, y_pred)\n",
    "print(\"r2 score: \",r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "075db38e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Mini Project: House Price Predictor\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.linear_model import Ridge, Lasso\n",
    "\n",
    "column_names = ['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD', 'TAX', 'PTRATIO', 'B', 'LSTAT', 'MEDV']\n",
    "data = pd.read_csv('housing.csv', header=None, delimiter=r\"\\s+\", names=column_names)\n",
    "\n",
    "X=data.drop('MEDV', axis=1)\n",
    "y=data['MEDV']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=100)\n",
    "\n",
    "model=LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "y_pred=model.predict(X_test)\n",
    "\n",
    "r2=r2_score(y_test, y_pred)\n",
    "print(\"R2 score for Linear Regression: \", r2)\n",
    "\n",
    "ridge_model=Ridge(alpha=1) # r2 score decreases on increasing alpha (observation)\n",
    "ridge_model.fit(X_train, y_train)\n",
    "y_ridge_pred=ridge_model.predict(X_test)\n",
    "r2_ridge=r2_score(y_test, y_ridge_pred)\n",
    "print(\"R2 score for Ridge Regression: \", r2_ridge)\n",
    "\n",
    "lasso_model=Lasso(alpha=1) # r2 score decreases on increasing alpha (observation)\n",
    "lasso_model.fit(X_train, y_train)\n",
    "y_lasso_pred=lasso_model.predict(X_test)\n",
    "r2_lasso=r2_score(y_test, y_lasso_pred)\n",
    "print(\"R2 score for Lasso Regression: \", r2_lasso)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86cf388a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Polynomial regression \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "df=pd.read_csv(\"poly_ds.csv\")\n",
    "X=df.iloc[:,0]\n",
    "y=df.iloc[:,1]\n",
    "X=X.values.reshape(-1,1)\n",
    "\n",
    "model=LinearRegression()\n",
    "model.fit(X,y)\n",
    "\n",
    "poly = PolynomialFeatures(degree=2)\n",
    "X_poly = poly.fit_transform(X)\n",
    "\n",
    "poly.fit(X_poly, y)\n",
    "lin2 = LinearRegression()\n",
    "lin2.fit(X_poly, y)\n",
    "\n",
    "plt.scatter(X, y, color='blue')\n",
    "plt.plot(X, model.predict(X), color='red')\n",
    "plt.title('Linear Regression')\n",
    "plt.xlabel('Temperature')\n",
    "plt.ylabel('Pressure')\n",
    "plt.show()\n",
    "\n",
    "plt.scatter(X, y, color='blue')\n",
    "plt.plot(X, lin2.predict(X_poly), color='red')\n",
    "plt.title('Polynomial Regression')\n",
    "plt.xlabel('Temperature')\n",
    "plt.ylabel('Pressure')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10614270",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Logistic Regression\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "df=pd.read_csv('D:\\\\AppStoneLab\\\\Day 1\\\\Titanic-Dataset.csv')\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "df=pd.get_dummies(data=df,columns=['Sex','Embarked'], dtype='int')\n",
    "\n",
    "df.drop(columns=['Name', 'Ticket', 'Cabin', 'PassengerId'], axis=1, inplace=True)\n",
    "df.head()\n",
    "\n",
    "X=df.drop('Survived', axis=1)\n",
    "y=df['Survived']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=100)\n",
    "\n",
    "model=LogisticRegression(solver='saga', random_state=100, max_iter=7000)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred=model.predict(X_test)\n",
    "\n",
    "accuracy=accuracy_score(y_test, y_pred)\n",
    "precision=precision_score(y_test, y_pred)\n",
    "recall=recall_score(y_test, y_pred)\n",
    "f1=f1_score(y_test, y_pred)\n",
    "roc_auc=roc_auc_score(y_test, y_pred)\n",
    "cm=confusion_matrix(y_true=y_test, y_pred=y_pred)\n",
    "\n",
    "print(\"Accuracy: \", accuracy)\n",
    "print(\"Precision: \", precision)\n",
    "print(\"Recall: \", recall)\n",
    "print(\"F1 score: \", f1)\n",
    "print(\"ROC_AUC score: \", roc_auc)\n",
    "\n",
    "sns.heatmap(cm, annot=True)\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.plot()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcd5baf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#KNN\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import f1_score, roc_auc_score, confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "df=pd.read_csv('KNNAlgorithmDataset.csv')\n",
    "df.drop('Unnamed: 32',axis=1, inplace=True)\n",
    "\n",
    "X=df.drop('diagnosis', axis=1)\n",
    "y=df['diagnosis'].map({'B': 0, 'M': 1})\n",
    "\n",
    "X_train, X_test, y_train, y_test= train_test_split(X, y, test_size=0.25, random_state=100)\n",
    "scaler=StandardScaler()\n",
    "X_train=scaler.fit_transform(X_train)\n",
    "X_test=scaler.transform(X_test)\n",
    "\n",
    "knn=KNeighborsClassifier()\n",
    "knn.fit(X_train, y_train)\n",
    "y_pred=knn.predict(X_test)\n",
    "\n",
    "f1=f1_score(y_test, y_pred)\n",
    "roc_auc=roc_auc_score(y_test, y_pred)\n",
    "cm=confusion_matrix(y_true=y_test, y_pred=y_pred)\n",
    "\n",
    "print(\"F1 score: \",f1)\n",
    "print(\"ROC_AUC score: \",roc_auc)\n",
    "sns.heatmap(cm, annot=True)\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32661f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SVM\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "\n",
    "df=pd.read_csv('KNNAlgorithmDataset.csv')\n",
    "df.drop('Unnamed: 32',axis=1, inplace=True)\n",
    "\n",
    "X=df.drop('diagnosis', axis=1)\n",
    "y=df['diagnosis'].map({'B': 0, 'M': 1})\n",
    "\n",
    "X_train, X_test, y_train, y_test= train_test_split(X, y, test_size=0.25, random_state=100)\n",
    "scaler=StandardScaler()\n",
    "X_train=scaler.fit_transform(X_train)\n",
    "X_test=scaler.transform(X_test)\n",
    "\n",
    "svc=SVC() #parameters can be changed(using default for now)\n",
    "svc.fit(X_train, y_train)\n",
    "y_pred = svc.predict(X_test)\n",
    "\n",
    "f1=f1_score(y_test, y_pred)\n",
    "roc_auc=roc_auc_score(y_test, y_pred)\n",
    "cm=confusion_matrix(y_true=y_test, y_pred=y_pred)\n",
    "\n",
    "print(\"F1 score: \",f1)\n",
    "print(\"ROC_AUC score: \",roc_auc)\n",
    "sns.heatmap(cm, annot=True)\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "293c0896",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gaussian naive bayes\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "df = pd.read_csv('D:\\\\AppStoneLab\\\\Day 2\\\\Iris.csv')\n",
    "\n",
    "X = df.drop(columns=['Id', 'Species'], axis=1)\n",
    "y = df['Species'].map({'Iris-setosa':0, 'Iris-versicolor':1, 'Iris-virginica':2})\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=100)\n",
    "\n",
    "gnb = GaussianNB()\n",
    "gnb.fit(X_train, y_train)\n",
    "\n",
    "y_pred_labels = gnb.predict(X_test)        # predicted class labels\n",
    "y_pred_prob = gnb.predict_proba(X_test)    # predicted probabilities (for ROC-AUC)\n",
    "\n",
    "\n",
    "f1 = f1_score(y_test, y_pred_labels, average=None)\n",
    "print(\"F1 score per class:\", f1)\n",
    "\n",
    "# ROC-AUC score (multiclass, weighted average)\n",
    "roc_auc = roc_auc_score(\n",
    "    y_test, \n",
    "    y_pred_prob, \n",
    "    multi_class='ovr', \n",
    "    average='macro'\n",
    ")\n",
    "print(\"ROC-AUC score:\", roc_auc)\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred_labels)\n",
    "sns.heatmap(cm, annot=True)\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bd796f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Multinomial Naive Bayes\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import f1_score, roc_auc_score, confusion_matrix\n",
    "\n",
    "df=pd.read_csv('spam.csv', encoding='iso8859_14')\n",
    "df.drop(columns=['Unnamed: 2', 'Unnamed: 3', 'Unnamed: 4'], axis=1, inplace=True)\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(df['v2'])\n",
    "y=df['v1'].map({'ham':0, 'spam':1})\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=100)\n",
    "\n",
    "mnb = MultinomialNB()\n",
    "mnb.fit(X_train, y_train)\n",
    "y_pred = mnb.predict(X_test)\n",
    "\n",
    "f1=f1_score(y_test, y_pred)\n",
    "roc_auc=roc_auc_score(y_test, y_pred)\n",
    "cm=confusion_matrix(y_true=y_test, y_pred=y_pred)\n",
    "\n",
    "print(\"F1 score: \",f1)\n",
    "print(\"ROC_AUC score: \",roc_auc)\n",
    "sns.heatmap(cm, annot=True)\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e1c582d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Decision Tree\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "\n",
    "df=pd.read_csv('D:\\\\AppStoneLab\\\\Day 2\\\\Iris.csv')\n",
    "\n",
    "X = df.drop(columns=['Id', 'Species'], axis=1)\n",
    "y = df['Species'].map({'Iris-setosa':0, 'Iris-versicolor':1, 'Iris-virginica':2})\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=100)\n",
    "\n",
    "DT=DecisionTreeClassifier(criterion='entropy')\n",
    "DT.fit(X_train, y_train)\n",
    "y_pred = DT.predict(X_test)\n",
    "\n",
    "f1=f1_score(y_test, y_pred, average=None)\n",
    "# roc_auc=roc_auc_score(y_test, y_pred, multi_class='ovr', average='macro')\n",
    "cm=confusion_matrix(y_true=y_test, y_pred=y_pred)\n",
    "\n",
    "print(\"F1 score: \",f1)\n",
    "# print(\"ROC_AUC score: \",roc_auc)\n",
    "sns.heatmap(cm, annot=True)\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.plot()\n",
    "\n",
    "plt.figure(figsize=(12,8))\n",
    "plot_tree(DT, feature_names=X.columns, class_names=['Setosa','Versicolor','Virginica'], filled=True, rounded=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "994de42c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Random Forest \n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "df=pd.read_csv('D:\\\\AppStoneLab\\\\Day 2\\\\Iris.csv')\n",
    "\n",
    "X = df.drop(columns=['Id', 'Species'], axis=1)\n",
    "y = df['Species'].map({'Iris-setosa':0, 'Iris-versicolor':1, 'Iris-virginica':2})\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=100)\n",
    "\n",
    "rf=RandomForestClassifier(n_estimators=100, random_state=100)\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred=rf.predict(X_test)\n",
    "\n",
    "f1=f1_score(y_test, y_pred, average=None)\n",
    "cm=confusion_matrix(y_true=y_test, y_pred=y_pred)\n",
    "\n",
    "print(\"F1 score: \",f1)\n",
    "sns.heatmap(cm, annot=True)\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.show()\n",
    "\n",
    "feature_importance = pd.Series(rf.feature_importances_, index=X.columns).sort_values(ascending=False)\n",
    "print(\"Feature Importance:\\n\", feature_importance)\n",
    "\n",
    "# Optional: plot feature importance\n",
    "feature_importance.plot(kind='bar')\n",
    "plt.ylabel('Importance')\n",
    "plt.title('Feature Importance from Random Forest')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1828dd2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
