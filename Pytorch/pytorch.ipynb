{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5383c44f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import nn\n",
    "from torch import optim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "842f591b",
   "metadata": {},
   "source": [
    "# Getting Started"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "824d4125",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.6375, 0.7364, 0.7428])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Tensor"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=torch.rand(3)\n",
    "print(x)\n",
    "type(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "fa606047",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "device = torch.accelerator.current_accelerator().type if torch.accelerator.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "552b9664",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1D tensor: tensor([1, 2, 3, 4, 5])\n",
      "\n",
      "2D Tensor: tensor([[1, 2],\n",
      "        [3, 4],\n",
      "        [5, 6]])\n",
      "\n",
      "3D Tensor: tensor([[[1, 2],\n",
      "         [3, 4]],\n",
      "\n",
      "        [[5, 6],\n",
      "         [7, 8]]])\n"
     ]
    }
   ],
   "source": [
    "t1=torch.tensor([1,2,3,4,5])\n",
    "print('1D tensor:',t1)\n",
    "\n",
    "t2=torch.tensor([[1,2],[3,4],[5,6]])\n",
    "print('\\n2D Tensor:',t2)\n",
    "\n",
    "t3=torch.tensor([[[1,2],[3,4]],[[5,6],[7,8]]])\n",
    "print('\\n3D Tensor:',t3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "25ed39b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random 2x3 tensor:\n",
      " tensor([[0.0929, 0.8024, 0.5947],\n",
      "        [0.1535, 0.9415, 0.4627]])\n",
      "\n",
      "2x3 tensor filled with zeros:\n",
      " tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]])\n",
      "\n",
      "2x3 tensor filled with ones:\n",
      " tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.]])\n",
      "\n",
      "2x3 empty tensor:\n",
      " tensor([[ 1.1364e-03, -4.8785e-05,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00]])\n"
     ]
    }
   ],
   "source": [
    "t4=torch.rand(2,3)\n",
    "print('random 2x3 tensor:\\n',t4)\n",
    "\n",
    "t5=torch.zeros(2,3)\n",
    "print('\\n2x3 tensor filled with zeros:\\n',t5)\n",
    "\n",
    "t6=torch.ones(2,3)\n",
    "print('\\n2x3 tensor filled with ones:\\n',t6)\n",
    "\n",
    "t7=torch.empty(2,3)\n",
    "print('\\n2x3 empty tensor:\\n',t7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "5c761326",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2D tensor:\n",
      " tensor([[1, 2],\n",
      "        [3, 4],\n",
      "        [5, 6]])\n",
      "\n",
      "First row: tensor([1, 2])\n",
      "\n",
      "First column: tensor([1, 3, 5])\n",
      "\n",
      "Last column: tensor([2, 4, 6])\n",
      "\n",
      "First 2 rows:\n",
      " tensor([[1, 2],\n",
      "        [3, 4]])\n"
     ]
    }
   ],
   "source": [
    "t8=torch.tensor([[1,2],[3,4],[5,6]])\n",
    "print('2D tensor:\\n',t8)\n",
    "\n",
    "print('\\nFirst row:',t8[0])\n",
    "\n",
    "print('\\nFirst column:',t8[:,0])\n",
    "\n",
    "print('\\nLast column:',t8[:,-1])\n",
    "\n",
    "print('\\nFirst 2 rows:\\n',t8[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "49cf2efc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original 2D tensor:\n",
      " tensor([[1, 2],\n",
      "        [3, 4],\n",
      "        [5, 6]])\n",
      "\n",
      "Reshaped 2D tensor:\n",
      " tensor([[1, 2, 3],\n",
      "        [4, 5, 6]])\n"
     ]
    }
   ],
   "source": [
    "t9=torch.tensor([[1,2],[3,4],[5,6]])\n",
    "t9_reshape=t9.view(2,3)\n",
    "print('Original 2D tensor:\\n',t9)\n",
    "\n",
    "print('\\nReshaped 2D tensor:\\n',t9_reshape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "40cc0137",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original 2D tensor:\n",
      " tensor([[1, 2, 3],\n",
      "        [4, 5, 6]])\n",
      "\n",
      "Added tensor:\n",
      " tensor([[11, 22, 33],\n",
      "        [14, 25, 36]])\n",
      "\n",
      "Matmul tensor:\n",
      " tensor([[14, 32],\n",
      "        [32, 77]])\n"
     ]
    }
   ],
   "source": [
    "t10=torch.tensor([[1,2,3],[4,5,6]])\n",
    "t11=torch.tensor([[10,20,30]])\n",
    "add=t10+t11\n",
    "print('Original 2D tensor:\\n',t10)\n",
    "\n",
    "print('\\nAdded tensor:\\n',add)\n",
    "\n",
    "matmul=torch.matmul(t10, t10.T)\n",
    "print('\\nMatmul tensor:\\n',matmul)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "48b98aaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Current GPU memory usage:\n",
      "Allocated: 0.12 MB\n",
      "Cached: 2.00 MB\n"
     ]
    }
   ],
   "source": [
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Using device: {device}')\n",
    "\n",
    "tensor_size = (100, 100)  \n",
    "a = torch.randn(tensor_size, device=device)  \n",
    "b = torch.randn(tensor_size, device=device)  \n",
    "\n",
    "c = a + b  \n",
    "\n",
    "\n",
    "print(\"Current GPU memory usage:\")\n",
    "print(f\"Allocated: {torch.cuda.memory_allocated(device) / (1024 ** 2):.2f} MB\")\n",
    "print(f\"Cached: {torch.cuda.memory_reserved(device) / (1024 ** 2):.2f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "767004fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Allocated: 0.00 MB\n",
      "Cached: 0.00 MB\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "gc.collect()\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "torch.cuda.empty_cache()\n",
    "print(f\"Allocated: {torch.cuda.memory_allocated(device) / (1024 ** 2):.2f} MB\")\n",
    "print(f\"Cached: {torch.cuda.memory_reserved(device) / (1024 ** 2):.2f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8db4308",
   "metadata": {},
   "source": [
    "# Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "57a14deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data=datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")\n",
    "test_data=datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=False, #extracts test data\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")\n",
    "\n",
    "batch_size=60\n",
    "train_dataloader=DataLoader(training_data, batch_size)\n",
    "test_dataloader=DataLoader(test_data, batch_size)\n",
    "\n",
    "labels_map = {\n",
    "    0: \"T-Shirt\",\n",
    "    1: \"Trouser\",\n",
    "    2: \"Pullover\",\n",
    "    3: \"Dress\",\n",
    "    4: \"Coat\",\n",
    "    5: \"Sandal\",\n",
    "    6: \"Shirt\",\n",
    "    7: \"Sneaker\",\n",
    "    8: \"Bag\",\n",
    "    9: \"Ankle Boot\",\n",
    "}\n",
    "\n",
    "classes = list(labels_map.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "47587270",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SimpleNN(\n",
      "  (fc1): Linear(in_features=2, out_features=4, bias=True)\n",
      "  (fc2): Linear(in_features=4, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        self.fc1=nn.Linear(2,4)\n",
    "        self.fc2=nn.Linear(4,1)\n",
    "    def forward(self,x):\n",
    "        x=torch.relu(self.fc1(x))\n",
    "        x=self.fc2(x)\n",
    "        return x\n",
    "model=SimpleNN()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "3bc70488",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [100/1000], Loss: 0.3065\n",
      "Epoch [200/1000], Loss: 0.2618\n",
      "Epoch [300/1000], Loss: 0.2404\n",
      "Epoch [400/1000], Loss: 0.2232\n",
      "Epoch [500/1000], Loss: 0.2077\n",
      "Epoch [600/1000], Loss: 0.1932\n",
      "Epoch [700/1000], Loss: 0.1803\n",
      "Epoch [800/1000], Loss: 0.1678\n",
      "Epoch [900/1000], Loss: 0.1556\n",
      "Epoch [1000/1000], Loss: 0.1436\n"
     ]
    }
   ],
   "source": [
    "X_train=torch.tensor([[0.0, 0.0], [0.0, 1.0], [1.0, 0.0], [1.0, 1.0]])\n",
    "y_train=torch.tensor([[0.0],[1.0],[1.0],[0.0]])\n",
    "\n",
    "model=SimpleNN()\n",
    "criterion=nn.MSELoss()\n",
    "optimizer=optim.SGD(model.parameters(), lr=0.005)\n",
    "\n",
    "\n",
    "for epoch in range(1000):\n",
    "    model.train()\n",
    "    outputs=model(X_train)\n",
    "    loss=criterion(outputs, y_train)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if (epoch + 1) % 100 == 0:\n",
    "        print(f'Epoch [{epoch+1}/1000], Loss: {loss.item():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "afa32de7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.3884],\n",
      "        [0.6384],\n",
      "        [0.5996],\n",
      "        [0.3633]])\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    test_data=torch.tensor([[0.0, 0.0], [0.0, 1.0], [1.0, 0.0], [1.0, 1.0]])\n",
    "    predictions=model(test_data)\n",
    "    print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d5190074",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.flatten=nn.Flatten()\n",
    "        self.linear_relu_stack=nn.Sequential(\n",
    "        nn.Linear(28*28,512),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(512,512),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(512,10)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        x=self.flatten(x)\n",
    "        logits=self.linear_relu_stack(x)\n",
    "        return logits\n",
    "\n",
    "model=NeuralNetwork()\n",
    "print(model)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "faf93b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn=nn.CrossEntropyLoss()\n",
    "optimizer=optim.SGD(model.parameters(), lr=0.003)\n",
    "\n",
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    size=len(dataloader.dataset)\n",
    "    model.train()\n",
    "    for batch, (X,y) in enumerate(dataloader):\n",
    "        pred=model(X)\n",
    "        loss=loss_fn(pred, y)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # if batch % 100 == 0:\n",
    "    loss, current = loss.item(), (batch + 1) * len(X)\n",
    "    print(f\"loss: {loss}  [{current}/{size}]\")\n",
    "            \n",
    "def test(dataloader, model, loss_fn):\n",
    "    size=len(dataloader.dataset)    \n",
    "    n_batches=len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct= 0,0\n",
    "    with torch.no_grad():\n",
    "        for X,y in dataloader:\n",
    "            pred=model(X)\n",
    "            test_loss+=loss_fn(pred, y).item()\n",
    "            correct+=(pred.argmax(1)==y).type(torch.float).sum().item()\n",
    "    test_loss/=n_batches\n",
    "    correct/=size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2973045d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:\n",
      "\n",
      "loss: 1.5082645416259766  [60000/60000]\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 1.473011 \n",
      "\n",
      "Epoch 2:\n",
      "\n",
      "loss: 1.0015138387680054  [60000/60000]\n",
      "Test Error: \n",
      " Accuracy: 66.0%, Avg loss: 0.959777 \n",
      "\n",
      "Epoch 3:\n",
      "\n",
      "loss: 0.846994161605835  [60000/60000]\n",
      "Test Error: \n",
      " Accuracy: 70.0%, Avg loss: 0.803486 \n",
      "\n",
      "Epoch 4:\n",
      "\n",
      "loss: 0.7590461373329163  [60000/60000]\n",
      "Test Error: \n",
      " Accuracy: 73.5%, Avg loss: 0.725632 \n",
      "\n",
      "Epoch 5:\n",
      "\n",
      "loss: 0.6968614459037781  [60000/60000]\n",
      "Test Error: \n",
      " Accuracy: 76.2%, Avg loss: 0.672210 \n",
      "\n",
      "Epoch 6:\n",
      "\n",
      "loss: 0.6495867371559143  [60000/60000]\n",
      "Test Error: \n",
      " Accuracy: 77.9%, Avg loss: 0.631773 \n",
      "\n",
      "Epoch 7:\n",
      "\n",
      "loss: 0.6136932373046875  [60000/60000]\n",
      "Test Error: \n",
      " Accuracy: 79.0%, Avg loss: 0.600784 \n",
      "\n",
      "Epoch 8:\n",
      "\n",
      "loss: 0.5865381360054016  [60000/60000]\n",
      "Test Error: \n",
      " Accuracy: 79.8%, Avg loss: 0.576731 \n",
      "\n",
      "Epoch 9:\n",
      "\n",
      "loss: 0.5661325454711914  [60000/60000]\n",
      "Test Error: \n",
      " Accuracy: 80.6%, Avg loss: 0.557673 \n",
      "\n",
      "Epoch 10:\n",
      "\n",
      "loss: 0.5501990914344788  [60000/60000]\n",
      "Test Error: \n",
      " Accuracy: 81.1%, Avg loss: 0.542264 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "epochs=10\n",
    "for i in range(epochs):\n",
    "    print(f\"Epoch {i+1}:\\n\")\n",
    "    train(train_dataloader, model, loss_fn, optimizer)\n",
    "    test(test_dataloader, model, loss_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "227b72fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: \"Ankle Boot\", Actual: \"Ankle Boot\"\n",
      "Predicted: \"Pullover\", Actual: \"Pullover\"\n",
      "Predicted: \"Trouser\", Actual: \"Trouser\"\n",
      "Predicted: \"Trouser\", Actual: \"Trouser\"\n",
      "Predicted: \"Shirt\", Actual: \"Shirt\"\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for i in range(5):\n",
    "        X, y = test_data[i][0], test_data[i][1]\n",
    "        pred = model(X)\n",
    "        predicted, actual = classes[pred[0].argmax(0)], classes[y]\n",
    "        print(f'Predicted: \"{predicted}\", Actual: \"{actual}\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "974e7c22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "linear_relu_stack.0.weight -- torch.Size([512, 784])\n",
      "linear_relu_stack.0.bias -- torch.Size([512])\n",
      "linear_relu_stack.2.weight -- torch.Size([512, 512])\n",
      "linear_relu_stack.2.bias -- torch.Size([512])\n",
      "linear_relu_stack.4.weight -- torch.Size([10, 512])\n",
      "linear_relu_stack.4.bias -- torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "for name, parameter in model.named_parameters():\n",
    "    print(name, \"--\",parameter.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5a7a219",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([20, 16, 50])\n",
      "torch.Size([20, 33, 24])\n",
      "Conv1d(16, 33, kernel_size=(3,), stride=(2,))\n"
     ]
    }
   ],
   "source": [
    "# Convolution 1D:\n",
    "m = nn.Conv1d(16, 33, 3, stride=2)\n",
    "input = torch.randn(20, 16, 50)\n",
    "output = m(input)\n",
    "print(input.size())\n",
    "print(output.size())\n",
    "# print(output)\n",
    "print(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2d764684",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([20, 16, 50, 100])\n",
      "torch.Size([20, 33, 24, 49])\n",
      "torch.Size([20, 33, 28, 100])\n",
      "torch.Size([20, 33, 26, 100])\n"
     ]
    }
   ],
   "source": [
    "# Convolution 2D\n",
    "\n",
    "m1 = nn.Conv2d(16, 33, 3, stride=2)\n",
    "\n",
    "m2 = nn.Conv2d(16, 33, (3, 5), stride=(2, 1), padding=(4, 2))\n",
    "\n",
    "m3 = nn.Conv2d(16, 33, (3, 5), stride=(2, 1), padding=(4, 2), dilation=(3, 1))\n",
    "input = torch.randn(20, 16, 50, 100)\n",
    "output1 = m1(input)\n",
    "output2 = m2(input)\n",
    "output3 = m3(input)\n",
    "\n",
    "print(input.size())\n",
    "print(output1.size())\n",
    "print(output2.size())\n",
    "print(output3.size())\n",
    "# print(output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0308826e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([20, 16, 10, 50, 50])\n",
      "torch.Size([20, 33, 5, 25, 25])\n",
      "torch.Size([20, 33, 8, 50, 49])\n"
     ]
    }
   ],
   "source": [
    "# Convolution 3D\n",
    "\n",
    "m1=nn.Conv3d(16, 33, 2, stride=2)\n",
    "m2=nn.Conv3d(16, 33, (3, 5, 2), stride=(2, 1, 1), padding=(4, 2, 0))\n",
    "input=torch.randn(20, 16, 10, 50, 50)\n",
    "output1=m1(input)\n",
    "output2=m2(input)\n",
    "print(input.size())\n",
    "print(output1.size())\n",
    "print(output2.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a989a7bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Dropout(p=0.2, inplace=False)\n",
      "    (3): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (4): ReLU()\n",
      "    (5): Dropout(p=0.2, inplace=False)\n",
      "    (6): Linear(in_features=512, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "#dropout \n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.flatten=nn.Flatten()\n",
    "        self.linear_relu_stack=nn.Sequential(\n",
    "        nn.Linear(28*28,512),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(0.2),\n",
    "        nn.Linear(512,512),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(0.2),\n",
    "        nn.Linear(512,10)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        x=self.flatten(x)\n",
    "        logits=self.linear_relu_stack(x)\n",
    "        return logits\n",
    "\n",
    "model=NeuralNetwork()\n",
    "print(model) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6b78c3b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:\n",
      "\n",
      "loss: 0.43239572644233704  [60000/60000]\n",
      "Test Error: \n",
      " Accuracy: 83.1%, Avg loss: 0.451494 \n",
      "\n",
      "Epoch 2:\n",
      "\n",
      "loss: 0.38935422897338867  [60000/60000]\n",
      "Test Error: \n",
      " Accuracy: 85.3%, Avg loss: 0.399360 \n",
      "\n",
      "Epoch 3:\n",
      "\n",
      "loss: 0.3372545540332794  [60000/60000]\n",
      "Test Error: \n",
      " Accuracy: 86.1%, Avg loss: 0.378803 \n",
      "\n",
      "Epoch 4:\n",
      "\n",
      "loss: 0.3212348222732544  [60000/60000]\n",
      "Test Error: \n",
      " Accuracy: 86.9%, Avg loss: 0.354543 \n",
      "\n",
      "Epoch 5:\n",
      "\n",
      "loss: 0.36041709780693054  [60000/60000]\n",
      "Test Error: \n",
      " Accuracy: 87.4%, Avg loss: 0.342899 \n",
      "\n",
      "Epoch 6:\n",
      "\n",
      "loss: 0.2732643187046051  [60000/60000]\n",
      "Test Error: \n",
      " Accuracy: 87.1%, Avg loss: 0.352029 \n",
      "\n",
      "Epoch 7:\n",
      "\n",
      "loss: 0.27149611711502075  [60000/60000]\n",
      "Test Error: \n",
      " Accuracy: 87.3%, Avg loss: 0.341071 \n",
      "\n",
      "Epoch 8:\n",
      "\n",
      "loss: 0.3338007628917694  [60000/60000]\n",
      "Test Error: \n",
      " Accuracy: 87.6%, Avg loss: 0.334360 \n",
      "\n",
      "Epoch 9:\n",
      "\n",
      "loss: 0.22312143445014954  [60000/60000]\n",
      "Test Error: \n",
      " Accuracy: 87.6%, Avg loss: 0.341208 \n",
      "\n",
      "Epoch 10:\n",
      "\n",
      "loss: 0.26701176166534424  [60000/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.1%, Avg loss: 0.333266 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "loss_fn=nn.CrossEntropyLoss()\n",
    "optimizer=optim.AdamW(model.parameters(), lr=0.001)\n",
    "\n",
    "def training(dataLoader, model, loss_fn, optimizer):\n",
    "    size=len(dataLoader.dataset)\n",
    "    model.train()\n",
    "    for batch, (X,y) in enumerate(dataLoader):\n",
    "        pred=model(X)\n",
    "        loss=loss_fn(pred, y)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # if batch % 100 == 0:\n",
    "    loss, current = loss.item(), (batch + 1) * len(X)\n",
    "    print(f\"loss: {loss}  [{current}/{size}]\")\n",
    "            \n",
    "def testing(dataLoader, model, loss_fn):\n",
    "    size=len(dataLoader.dataset)    \n",
    "    n_batches=len(dataLoader)\n",
    "    model.eval()\n",
    "    test_loss, correct= 0,0\n",
    "    with torch.no_grad():\n",
    "        for X,y in dataLoader:\n",
    "            pred=model(X)\n",
    "            test_loss+=loss_fn(pred, y).item()\n",
    "            correct+=(pred.argmax(1)==y).type(torch.float).sum().item()\n",
    "    test_loss/=n_batches\n",
    "    correct/=size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n",
    "    \n",
    "epochs=10\n",
    "for i in range(epochs):\n",
    "    print(f\"Epoch {i+1}:\\n\")\n",
    "    training(train_dataloader, model, loss_fn, optimizer)\n",
    "    testing(test_dataloader, model, loss_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b97f4dee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: \"Trouser\", Actual: \"Trouser\"\n",
      "Predicted: \"Pullover\", Actual: \"Pullover\"\n",
      "Predicted: \"Pullover\", Actual: \"Coat\"\n",
      "Predicted: \"Bag\", Actual: \"Bag\"\n",
      "Predicted: \"T-Shirt\", Actual: \"T-Shirt\"\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for i in range(15,20):\n",
    "        X, y = test_data[i][0], test_data[i][1]\n",
    "        pred = model(X)\n",
    "        predicted, actual = classes[pred[0].argmax(0)], classes[y]\n",
    "        print(f'Predicted: \"{predicted}\", Actual: \"{actual}\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e7a24789",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'CNN' object has no attribute 'fc'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[49]\u001b[39m\u001b[32m, line 30\u001b[39m\n\u001b[32m     27\u001b[39m         x= \u001b[38;5;28mself\u001b[39m.fc(x)\n\u001b[32m     28\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m x\n\u001b[32m---> \u001b[39m\u001b[32m30\u001b[39m model=\u001b[43mCNN\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     31\u001b[39m \u001b[38;5;28mprint\u001b[39m(model)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[49]\u001b[39m\u001b[32m, line 12\u001b[39m, in \u001b[36mCNN.__init__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     10\u001b[39m \u001b[38;5;28mself\u001b[39m.pool= nn.MaxPool2d(\u001b[32m2\u001b[39m)\n\u001b[32m     11\u001b[39m \u001b[38;5;28mself\u001b[39m.fc_shape=\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msize_tracker\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrandn\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m28\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m28\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     14\u001b[39m \u001b[38;5;28mself\u001b[39m.fc= nn.Linear(\u001b[38;5;28mself\u001b[39m.fc_shape, \u001b[32m10\u001b[39m)\n\u001b[32m     15\u001b[39m \u001b[38;5;28mself\u001b[39m.flat= nn.Flatten()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[49]\u001b[39m\u001b[32m, line 20\u001b[39m, in \u001b[36mCNN.size_tracker\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m     18\u001b[39m x= \u001b[38;5;28mself\u001b[39m.pool(\u001b[38;5;28mself\u001b[39m.relu(\u001b[38;5;28mself\u001b[39m.conv1(x)))\n\u001b[32m     19\u001b[39m x= \u001b[38;5;28mself\u001b[39m.pool(\u001b[38;5;28mself\u001b[39m.relu(\u001b[38;5;28mself\u001b[39m.conv2(x)))\n\u001b[32m---> \u001b[39m\u001b[32m20\u001b[39m x= \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfc\u001b[49m(x)\n\u001b[32m     21\u001b[39m \u001b[38;5;28mself\u001b[39m.fc_shape= x[\u001b[32m0\u001b[39m].shape[\u001b[32m0\u001b[39m]*x[\u001b[32m0\u001b[39m].shape[\u001b[32m1\u001b[39m]*x[\u001b[32m0\u001b[39m].shape[\u001b[32m2\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python314\\site-packages\\torch\\nn\\modules\\module.py:1964\u001b[39m, in \u001b[36mModule.__getattr__\u001b[39m\u001b[34m(self, name)\u001b[39m\n\u001b[32m   1962\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m modules:\n\u001b[32m   1963\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m modules[name]\n\u001b[32m-> \u001b[39m\u001b[32m1964\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[32m   1965\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m).\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m object has no attribute \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1966\u001b[39m )\n",
      "\u001b[31mAttributeError\u001b[39m: 'CNN' object has no attribute 'fc'"
     ]
    }
   ],
   "source": [
    "#CNN\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1= nn.Conv2d(1, 64, 2)\n",
    "        self.conv2= nn.Conv2d(64, 128, 2)\n",
    "        \n",
    "        self.relu= nn.ReLU()\n",
    "        self.pool= nn.MaxPool2d(2)\n",
    "        self.fc_shape=None\n",
    "        self.size_tracker(torch.randn(1, 1, 28, 28))\n",
    "        \n",
    "        self.fc= nn.Linear(self.fc_shape, 10)\n",
    "        self.flat= nn.Flatten()\n",
    "        \n",
    "    def size_tracker(self, x):\n",
    "        x= self.pool(self.relu(self.conv1(x)))\n",
    "        x= self.pool(self.relu(self.conv2(x)))\n",
    "        x= self.fc(x)\n",
    "        self.fc_shape= x[0].shape[0]*x[0].shape[1]*x[0].shape[2]\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x= self.pool(self.relu(self.conv1(x)))\n",
    "        x= self.pool(self.relu(self.conv2(x)))\n",
    "        x= self.flat(x)\n",
    "        x= self.fc(x)\n",
    "        return x\n",
    "\n",
    "model=CNN()\n",
    "print(model)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f0822d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn=nn.CrossEntropyLoss()\n",
    "optimizer=optim.AdamW(model.parameters(), lr=0.0001)\n",
    "\n",
    "\n",
    "def training(dataLoader, model, loss_fn, optimizer):\n",
    "    size=len(dataLoader.dataset)\n",
    "    model.train()\n",
    "    for batch, (X,y) in enumerate(dataLoader):\n",
    "        pred=model(X)\n",
    "        loss=loss_fn(pred, y)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # if batch % 100 == 0:\n",
    "    loss, current = loss.item(), (batch + 1) * len(X)\n",
    "    print(f\"loss: {loss}  [{current}/{size}]\")\n",
    "\n",
    "def testing(dataLoader, model, loss_fn):\n",
    "    size=len(dataLoader.dataset)    \n",
    "    n_batches=len(dataLoader)\n",
    "    model.eval()\n",
    "    test_loss, correct= 0,0\n",
    "    with torch.no_grad():\n",
    "        for X,y in dataLoader:\n",
    "            pred=model(X)\n",
    "            test_loss+=loss_fn(pred, y).item()\n",
    "            correct+=(pred.argmax(1)==y).type(torch.float).sum().item()\n",
    "    test_loss/=n_batches\n",
    "    correct/=size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6ac0f91a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:\n",
      "\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (60x2304 and 1024x512)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[44]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epoch):\n\u001b[32m      3\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi+\u001b[32m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m     \u001b[43mtraining\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      5\u001b[39m     testing(test_dataloader, model, loss_fn)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[43]\u001b[39m\u001b[32m, line 9\u001b[39m, in \u001b[36mtraining\u001b[39m\u001b[34m(dataLoader, model, loss_fn, optimizer)\u001b[39m\n\u001b[32m      7\u001b[39m model.train()\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m batch, (X,y) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(dataLoader):\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m     pred=\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     10\u001b[39m     loss=loss_fn(pred, y)\n\u001b[32m     12\u001b[39m     optimizer.zero_grad()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python314\\site-packages\\torch\\nn\\modules\\module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python314\\site-packages\\torch\\nn\\modules\\module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[42]\u001b[39m\u001b[32m, line 20\u001b[39m, in \u001b[36mCNN.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m     19\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[32m---> \u001b[39m\u001b[32m20\u001b[39m     x=\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcnn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     21\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python314\\site-packages\\torch\\nn\\modules\\module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python314\\site-packages\\torch\\nn\\modules\\module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python314\\site-packages\\torch\\nn\\modules\\container.py:250\u001b[39m, in \u001b[36mSequential.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    246\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    247\u001b[39m \u001b[33;03mRuns the forward pass.\u001b[39;00m\n\u001b[32m    248\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    249\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m250\u001b[39m     \u001b[38;5;28minput\u001b[39m = \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    251\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python314\\site-packages\\torch\\nn\\modules\\module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python314\\site-packages\\torch\\nn\\modules\\module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python314\\site-packages\\torch\\nn\\modules\\linear.py:134\u001b[39m, in \u001b[36mLinear.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    130\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) -> Tensor:\n\u001b[32m    131\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    132\u001b[39m \u001b[33;03m    Runs the forward pass.\u001b[39;00m\n\u001b[32m    133\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m134\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mRuntimeError\u001b[39m: mat1 and mat2 shapes cannot be multiplied (60x2304 and 1024x512)"
     ]
    }
   ],
   "source": [
    "epoch=10\n",
    "for i in range(epoch):\n",
    "    print(f\"Epoch {i+1}:\\n\")\n",
    "    training(train_dataloader, model, loss_fn, optimizer)\n",
    "    testing(test_dataloader, model, loss_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf27a7e9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
